<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="A Second Semester Statistics Course with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A Second Semester Statistics Course with R">

<title>A Second Semester Statistics Course with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and table plots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section2-2" class="section level2">
<h2><span class="header-section-number">2.2</span> Beanplots</h2>
<p>The other graphical display for comparing multiple groups we will use is a display called a <strong><em>beanplot</em></strong> <span class="citation">(Kampstra <a href="#ref-Kampstra2008">2008</a>)</span>. Figure <a href="2-2-section2-2.html#fig:Figure2-5">2.5</a> shows an example of a beanplot that provides a side-by-side display that contains the density curves, the original observations that generated the density curve in a (jittered) rug-plot, the mean of each group, and the overall mean of the entire data set. For each group, the density curves are mirrored to aid in visual assessment of the shape of the distribution, which makes a “bean” of sorts. This mirroring also creates a shape that resembles a violin with skewed distributions so this display has also been called a “violin plot”. The beanplot includes bold horizontal lines at the mean for each group and adds a lighter dashed line for the overall mean to allow comparison of that global mean with the individual group means. All together this plot shows us information on the center (mean), spread, and shape of the distributions of the responses. Our inferences typically focus on the means of the groups and this plot allows us to compare those across the groups while gaining information on the shapes of the distributions of responses in each group.</p>
<p>To use the <code>beanplot</code> function we need to install and then load the <code>beanplot</code> package <span class="citation">(Kampstra <a href="#ref-R-beanplot">2014</a>)</span>. The function works like the boxplot used previously except that options for <code>log</code>, <code>col</code>, and <code>method</code> need to be specified. Use these<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> options for any beanplots you make: <code>log=&quot;&quot;, col=&quot;bisque&quot;, method=&quot;jitter&quot;</code>.</p>

<div class="figure"><span id="fig:Figure2-5"></span>
<img src="02-reintroductionToStatistics_files/figure-html/Figure2-5-1.png" alt="Beanplot of Years by picture group. Long, bold lines correspond to mean of each group, dashed line for overall or global mean." width="480" />
<p class="caption">
Figure 2.5: Beanplot of Years by picture group. Long, bold lines correspond to mean of each group, dashed line for overall or global mean.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(beanplot)
<span class="kw">beanplot</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury, <span class="dt">log=</span><span class="st">&quot;&quot;</span>, <span class="dt">col=</span><span class="st">&quot;bisque&quot;</span>, <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>)</code></pre></div>
<p>Figure <a href="2-2-section2-2.html#fig:Figure2-5">2.5</a> reinforces the strong right skews that were also detected in the boxplots previously. The three large sentences of 15 years can now be clearly identified, with one in the <em>Beautiful</em> group and two in the <em>Unattractive</em> group. The <em>Unattractive</em> group seems to have more high observations than the other groups even though the <em>Beautiful</em> group had the largest number of observations around 10 years. The mean sentence was highest for the <em>Unattractive</em> group and the difference in the means between <em>Beautiful</em> and <em>Average</em> was small.</p>
<p>In this example, it appears that the mean for <em>Unattractive</em> is larger than the other two groups. But is this difference real? We will never know the answer to that question, but we can assess how likely we are to have seen a result as extreme or more extreme than our result, assuming that there is no difference in the means of the groups. And if the observed result is (extremely) unlikely to occur, then we can reject the hypothesis that the groups have the same mean and conclude that there is evidence of a real difference. To start exploring whether there are differences in the means, we need to have numerical values to compare. We can get means and standard deviations by groups easily using the same formula notation with the <code>mean</code> and <code>sd</code> functions if the <code>mosaic</code> package is loaded.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(mosaic)
<span class="kw">mean</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##     4.333333     3.973684     5.810811</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##     3.405362     2.823519     4.364235</code></pre>
<p>We can also use the <code>favstats</code> function to get those summaries and others by groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">favstats</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##           Attr min Q1 median   Q3 max     mean       sd  n missing
## 1    Beautiful   1  2      3  6.5  15 4.333333 3.405362 39       0
## 2      Average   1  2      3  5.0  12 3.973684 2.823519 38       0
## 3 Unattractive   1  2      5 10.0  15 5.810811 4.364235 37       0</code></pre>
<p>Based on these results, we can see that there is an estimated difference of almost 2 years in the mean sentence between <em>Average</em> and <em>Unattractive</em> groups. Because there are three groups being compared in this study, we will have to wait until Chapter 3 and the One-Way ANOVA test to fully assess evidence related to some difference among the three groups. For now, we are going to focus on comparing the mean <em>Years</em> between <em>Average</em> and <em>Unattractive</em> groups – which is a <strong><em>2 independent sample mean</em></strong> situation and something you should have seen before. Remember that the “independent” sample part of this refers to observations that are independently observed for the two groups as opposed to the paired sample situation that you may have explored where one observation from the first group is related to an observation in the second group (two measures on the same person (we generically call this “repeated measures”) or the famous “twin” studies with one twin assigned to each group).</p>
<p>Here we are going to use the “simple” two independent group scenario to review some basic statistical concepts and connect two different frameworks for conducting statistical inference: randomization and parametric inference techniques. <strong><em>Parametric</em></strong> statistical methods involve making assumptions about the distribution of the responses and obtaining confidence intervals and/or p-values using a <em>named</em> distribution (like the <span class="math inline">\(z\)</span> or <span class="math inline">\(t\)</span>-distributions). Typically these results are generated using formulas and looking up areas under curves or cutoffs using a table or a computer. <strong><em>Randomization</em></strong>-based statistical methods use a computer to shuffle, sample, or simulate observations in ways that allow you to obtain distributions of possible results to find areas and cutoffs without resorting to using tables and named distributions. Randomization methods are what are called <strong><em>nonparametric</em></strong> methods that often make fewer assumptions (they are <strong><em>not free of assumptions</em></strong>!) and so can handle a larger set of problems more easily than parametric methods. When the assumptions involved in the parametric procedures are met by a data set, the randomization methods often provide very similar results to those provided by the parametric techniques. To be a more sophisticated statistical consumer, it is useful to have some knowledge of both of these techniques for performing statistical inference and the fact that they can provide similar results might deepen your understanding of both approaches.</p>
<p>We will start with comparing the <em>Average</em> and <em>Unattractive</em> groups to compare these two ways of doing inference. We could remove the <em>Beautiful</em> group observations in a spreadsheet program and read that new data set back into R, but it is actually pretty easy to use R to do data management once the data set is loaded. To remove the observations that came from the <em>Beautiful</em> group, we are going to generate a new variable that we will call <code>NotBeautiful</code> that is true when observations came from another group (<em>Average</em> or <em>Unattractive</em>) and false for observations from the <em>Beautiful</em> group. To do this, we will apply the <strong><em>not equal</em></strong> logical function (<code>!=</code> ) to the variable <code>Attr</code>, inquiring whether it was different from the <code>&quot;Beautiful&quot;</code> level. You can see the content of the new variable in the output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MockJury<span class="op">$</span>NotBeautiful &lt;-<span class="st"> </span>MockJury<span class="op">$</span>Attr <span class="op">!=</span><span class="st"> &quot;Beautiful&quot;</span>
MockJury<span class="op">$</span>NotBeautiful</code></pre></div>
<pre><code>##   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
##  [23]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [34]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [45]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [56]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [67]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
##  [78] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [89] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [100]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [111]  TRUE  TRUE  TRUE  TRUE</code></pre>
<p>This new variable is only FALSE for the <em>Beautiful</em> responses as we can see if we compare some of the results from the original and new variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">tibble</span>(MockJury<span class="op">$</span>Attr, MockJury<span class="op">$</span>NotBeautiful))</code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   `MockJury$Attr` `MockJury$NotBeautiful`
##   &lt;fctr&gt;          &lt;lgl&gt;                  
## 1 Beautiful       F                      
## 2 Beautiful       F                      
## 3 Beautiful       F                      
## 4 Beautiful       F                      
## 5 Beautiful       F                      
## 6 Beautiful       F</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(<span class="kw">tibble</span>(MockJury<span class="op">$</span>Attr, MockJury<span class="op">$</span>NotBeautiful))</code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   `MockJury$Attr` `MockJury$NotBeautiful`
##   &lt;fctr&gt;          &lt;lgl&gt;                  
## 1 Average         T                      
## 2 Average         T                      
## 3 Average         T                      
## 4 Average         T                      
## 5 Average         T                      
## 6 Average         T</code></pre>
<p>To get rid of one of the responses that are in one of the groups, we need to learn a little bit about data management in R. <strong><em>Brackets</em></strong> <code>([,])</code> are used to access and possibly modify the rows or columns in a tibble with entries before the comma operating on rows and entries after the comma on the columns. For example, if you want to see the results for the 5<sup>th</sup> subject, you can reference the 5<sup>th</sup> row of the tibble using <code>[5,]</code> after the tibble name:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MockJury[<span class="dv">5</span>,]</code></pre></div>
<pre><code>##        Attr    Crime Years Serious exciting calm independent sincere warm
## 5 Beautiful Burglary     7       9        1    1           5       1    8
##   phyattr sociable kind intelligent strong sophisticated happy ownPA
## 5       8        9    4           7      9             9     8     7
##   NotBeautiful
## 5        FALSE</code></pre>
<p>We could just extract the <em>Years</em> response for the 5<sup>th</sup> subject by incorporating information on the row and column of interest (<code>Years</code> is the 3<sup>rd</sup> column):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MockJury[<span class="dv">5</span>,<span class="dv">3</span>]</code></pre></div>
<pre><code>## [1] 7</code></pre>
<p>In R, we can use logical vectors to keep any rows of the tibble where the variable is true and drop any rows where it is false by placing the logical variable in the first element of the brackets. The reduced version of the data set should be saved with a different name such as <code>MockJury2</code> that is used here to reduce the chances of confusing it with the previous full data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MockJury2 &lt;-<span class="st"> </span>MockJury[MockJury<span class="op">$</span>NotBeautiful,]</code></pre></div>
<p>You will always want to check that the correct observations were dropped either using <code>View(MockJury2)</code> or by doing a quick summary of the <code>Attr</code> variable in the new tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(MockJury2<span class="op">$</span>Attr)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##            0           38           37</code></pre>
<p>It ends up that R remembers the <em>Beautiful</em> category even though there are 0 observations in it now and that can cause us some problems. When we remove a group of observations<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a>, we sometimes need to clean up categorical variables to just reflect the categories that are present. The <code>factor</code> function creates categorical variables based on the levels of the variables that are observed and is useful to run here to clean up <code>Attr</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MockJury2<span class="op">$</span>Attr &lt;-<span class="st"> </span><span class="kw">factor</span>(MockJury2<span class="op">$</span>Attr) 
<span class="kw">summary</span>(MockJury2<span class="op">$</span>Attr)</code></pre></div>
<pre><code>##      Average Unattractive 
##           38           37</code></pre>
<p>Now if we remake the boxplots and beanplots, they only contain results for the two groups of interest here as seen in Figure <a href="2-2-section2-2.html#fig:Figure2-6">2.6</a>.</p>

<div class="figure"><span id="fig:Figure2-6"></span>
<img src="02-reintroductionToStatistics_files/figure-html/Figure2-6-1.png" alt="Boxplot and beanplot of the Years responses on the reduced MockJury2 data set." width="552" />
<p class="caption">
Figure 2.6: Boxplot and beanplot of the <em>Years</em> responses on the reduced <code>MockJury2</code> data set.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury2) 
<span class="kw">beanplot</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury2, <span class="dt">log=</span><span class="st">&quot;&quot;</span>, <span class="dt">col=</span><span class="st">&quot;bisque&quot;</span>, <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>)</code></pre></div>
<p>The two-sample mean techniques you learned in your previous course all start with comparing the means the two groups. We can obtain the two means using the <code>mean</code> function or directly obtain the difference in the means using the <code>diffmean</code> function (both require the <code>mosaic</code> package). The <code>diffmean</code> function provides <span class="math inline">\(\bar{x}_\text{Unattractive} - \bar{x}_\text{Average}\)</span> where <span class="math inline">\(\bar{x}\)</span> (read as “x-bar”) is the sample mean of observations in the subscripted group. Note that there are two directions that you could compare the means and this function chooses to take the mean from the second group name <em>alphabetically</em> and subtract the mean from the first alphabetical group name. It is always good to check the direction of this calculation as having a difference of <span class="math inline">\(-1.84\)</span> years versus <span class="math inline">\(1.84\)</span> years could be important.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury2)</code></pre></div>
<pre><code>##      Average Unattractive 
##     3.973684     5.810811</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diffmean</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury2)</code></pre></div>
<pre><code>## diffmean 
## 1.837127</code></pre>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Kampstra2008">
<p>Kampstra, Peter. 2008. “Beanplot: A Boxplot Alternative for Visual Comparison of Distributions.” <em>Journal of Statistical Software, Code Snippets</em> 28 (1): 1–9. <a href="http://www.jstatsoft.org/v28/c01/" class="uri">http://www.jstatsoft.org/v28/c01/</a>.</p>
</div>
<div id="ref-R-beanplot">
<p>Kampstra, Peter. 2014. <em>Beanplot: Visualization via Beanplots (Like Boxplot/Stripchart/Violin Plot)</em>. <a href="https://CRAN.R-project.org/package=beanplot" class="uri">https://CRAN.R-project.org/package=beanplot</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="17">
<li id="fn17"><p>Well, you can use other colors (try “lightblue” for example), but I think bisque looks nice in these plots.<a href="2-2-section2-2.html#fnref17">↩</a></p></li>
<li id="fn18"><p>It is also possible to use the <code>subset</code> function to eliminate observations that do not have a particular trait and <code>subset(MockJury,subset=NotBeautiful)</code> would provide the same result as <code>MockJury[MockJury$NotBeautiful,]</code> did here.<a href="2-2-section2-2.html#fnref18">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="2-1-section2-1.html"><button class="btn btn-default">Previous</button></a>
<a href="2-3-section2-3.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
