<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="A Second Semester Statistics Course with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A Second Semester Statistics Course with R">

<title>A Second Semester Statistics Course with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and table plots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section3-2" class="section level2">
<h2><span class="header-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</h2>
<p>We introduced the statistical model <span class="math inline">\(y_{ij} = \mu_j+\varepsilon_{ij}\)</span> in Chapter <a href="2-chapter2.html#chapter2">2</a> for the situation with <span class="math inline">\(j = 1 \text{ or } 2\)</span> to denote a situation where there were two groups and, for the model that is consistent with the alternative hypothesis, the means differed. Now we have three groups and the previous model can be extended to this new situation by allowing <span class="math inline">\(j\)</span> to be 1, 2, or 3. Now that we have more than two groups, we need to admit that what we were doing in Chapter <a href="2-chapter2.html#chapter2">2</a> was actually fitting what is called a <strong><em>linear model</em></strong>. The linear model assumes that the responses follow a normal distribution with the linear model defining the mean, all observations have the same variance, and the parameters for the mean in the model enter linearly. This last condition is hard to explain at this level of material – it is sufficient to know that there are models where the parameters enter the model nonlinearly and that they are beyond the scope of this function and this material. By employing a general modeling methodology, we will be able to use the same general modeling framework for the methods in Chapters <a href="3-chapter3.html#chapter3"><strong>??</strong></a>, <a href="4-chapter4.html#chapter4"><strong>??</strong></a>, <a href="6-chapter6.html#chapter6"><strong>??</strong></a>, <a href="7-chapter7.html#chapter7"><strong>??</strong></a>, and <a href="8-chapter8.html#chapter8"><strong>??</strong></a>.</p>
<p>As in Chapter <a href="2-chapter2.html#chapter2">2</a>, we have a null hypothesis that defines a situation (and model) where all the groups have the same mean. Specifically, the <strong><em>null hypothesis</em></strong> in the general situation with <span class="math inline">\(J\)</span> groups (<span class="math inline">\(J\ge 2\)</span>) is to have all the <span class="math inline">\(\underline{\text{true}}\)</span> group means equal,</p>
<p><span class="math display">\[H_0:\mu_1 = \ldots \mu_J.\]</span></p>
<p>This defines a model where all the groups have the same mean so it can be defined in terms of a single mean, <span class="math inline">\(\mu\)</span>, for the <span class="math inline">\(i^{th}\)</span> observation from the <span class="math inline">\(j^{th}\)</span> group as <span class="math inline">\(y_{ij} = \mu+\varepsilon_{ij}\)</span>. This is not the model that most researchers want to be the final description of their study as it implies no difference in the groups. There is more caution required to specify the alternative hypothesis with more than two groups. The <strong><em>alternative hypothesis</em></strong> needs to be the logical negation of this null hypothesis of all groups having equal means; to make the null hypothesis false, we only need one group to differ but more than one group could differ from the others. Essentially, there are many ways to “violate” the null hypothesis so we choose some delicate wording for the alternative hypothesis when there are more than 2 groups. Specifically, we state the alternative as</p>
<p><span class="math display">\[H_A: \text{ Not all } \mu_j \text{ are equal}\]</span></p>
<p>or, in words, <strong>at least one of the true means differs among the J groups</strong>. You will be attracted to trying to say that all means are different in the alternative but we do not put this strict a requirement in place to reject the null hypothesis. The alternative model allows all the true group means to differ but does require that they differ with</p>
<p><span class="math display">\[y_{ij} = {\color{red}{\mu_j}}+\varepsilon_{ij}.\]</span></p>
<p>This linear model states that the response for the <span class="math inline">\(i^{th}\)</span> observation in the <span class="math inline">\(j^{th}\)</span> group, <span class="math inline">\(\mathbf{y_{ij}}\)</span>, is modeled with a group <span class="math inline">\(j\)</span> (<span class="math inline">\(j=1, \ldots, J\)</span>) population mean, <span class="math inline">\(\mu_j\)</span>, and a random error for each subject in each group <span class="math inline">\(\varepsilon_{ij}\)</span>, that we assume follows a normal distribution and that all the random errors have the same variance, <span class="math inline">\(\sigma^2\)</span>. We can write the assumption about the random errors, often called the <strong><em>normality assumption</em></strong>, as <span class="math inline">\(\varepsilon_{ij} \sim N(0,\sigma^2)\)</span>. There is a second way to write out this model that allows extension to more complex models discussed below, so we need a name for this version of the model. The model written in terms of the <span class="math inline">\({\color{red}{\mu_j}}\text{&#39;s}\)</span> is called the <b><font color='red'>cell means model</font></b> and is the easier version of this model to understand.</p>
<p>One of the reasons we learned about beanplots is that it helps us visually consider all the aspects of this model. In the right panel of Figure <a href="3-1-section3-1.html#fig:Figure3-1">2.23</a>, we can see the wider, bold horizontal lines that provide the estimated group means. The bigger the differences in the sample means, the more likely we are to find evidence against the null hypothesis. You can also see the null model on the plot that assumes all the groups have the same mean as displayed in the dashed horizontal line at 4.7 years (the R code below shows the overall mean of <em>Years</em> is 4.7). While the hypotheses focus on the means, the model also contains assumptions about the distribution of the responses – specifically that the distributions are normal and that all the groups have the same variability. As discussed previously, it appears that the distributions are right skewed and the variability might not be the same for all the groups. The boxplot provides the information about the skew and variability but since it doesn’t display the means it is not directly related to the linear model and hypotheses we are considering.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(MockJury<span class="op">$</span>Years)</code></pre></div>
<pre><code>## [1] 4.692982</code></pre>
<p>There is a second way to write out the One-Way ANOVA model that provides a framework for extensions to more complex models described in Chapter <a href="4-chapter4.html#chapter4"><strong>??</strong></a> and beyond. The other <strong><em>parameterization</em></strong> (way of writing out or defining) of the model is called the <b><font color='purple'>reference-coded model</font></b> since it writes out the model in terms of a <strong><em>baseline group</em></strong> and deviations from that baseline or reference level. The reference-coded model for the <span class="math inline">\(i^{th}\)</span> subject in the <span class="math inline">\(j^{th}\)</span> group is <span class="math inline">\(y_{ij} ={\color{purple}{\boldsymbol{\alpha + \tau_j}}}+\varepsilon_{ij}\)</span> where <span class="math inline">\(\color{purple}{\boldsymbol{\alpha}}\)</span> (alpha) is the true mean for the baseline group (first alphabetically) and the <span class="math inline">\(\color{purple}{\boldsymbol{\tau_j}}\)</span> (tau <span class="math inline">\(j\)</span>) are the deviations from the baseline group for group <span class="math inline">\(j\)</span>. The deviation for the baseline group, <span class="math inline">\(\color{purple}{\boldsymbol{\tau_1}}\)</span>, is always set to 0 so there are really just deviations for groups 2 through <span class="math inline">\(J\)</span>. The equivalence between the two models can be seen by considering the mean for the first, second, and <span class="math inline">\(J^{th}\)</span> groups in both models:</p>
<p><span class="math display">\[\begin{array}{lccc}
&amp; \textbf{Cell means:} &amp;&amp; \textbf{Reference-coded:}\\
\textbf{Group } 1: &amp; \color{red}{\mu_1} &amp;&amp; \color{purple}{\boldsymbol{\alpha}} \\
\textbf{Group } 2: &amp; \color{red}{\mu_2} &amp;&amp; \color{purple}{\boldsymbol{\alpha + \tau_2}} \\
\ldots &amp; \ldots &amp;&amp; \ldots \\
\textbf{Group } J: &amp; \color{red}{\mu_J} &amp;&amp; \color{purple}{\boldsymbol{\alpha +\tau_J}}
\end{array}\]</span></p>
<p>The hypotheses for the reference-coded model are similar to those in the cell-means coding except that they are defined in terms of the deviations, <span class="math inline">\({\color{purple}{\boldsymbol{\tau_j}}}\)</span>. The null hypothesis is that there is no deviation from the baseline for any group – that all the <span class="math inline">\({\color{purple}{\boldsymbol{\tau_j\text{&#39;s}}}}=0\)</span>,</p>
<p><span class="math display">\[\boldsymbol{H_0: \tau_2=\ldots=\tau_J=0}.\]</span></p>
<p>The alternative hypothesis is that at least one of the deviations is not 0,</p>
<p><span class="math display">\[\boldsymbol{H_A:} \textbf{ Not all } \boldsymbol{\tau_j} \textbf{ equal } \bf{0}.\]</span></p>
<p>In this chapter, you are welcome to use either version (unless we instruct you otherwise) but we have to use the reference-coding in subsequent chapters. The next task is to learn how to use R’s linear model, <code>lm</code>, function to get estimates of the parameters in each model, but first a quick review of these new ideas:</p>
<p><b><font color='red'>Cell Means Version</font></b></p>
<ul>
<li><p><span class="math inline">\(H_0: {\color{red}{\mu_1=\ldots\mu_J}}\)</span>             <span class="math inline">\(H_A: {\color{red}{\text{ Not all } \mu_j \text{ equal}}}\)</span></p></li>
<li><p>Null hypothesis in words: No difference in the true means between the groups.</p></li>
<li><p>Null model: <span class="math inline">\(y_{ij} = \mu_j+\varepsilon_{ij}\)</span></p></li>
<li><p>Alternative hypothesis in words: At least one of the true means differs between the groups.</p></li>
<li><p>Alternative model: <span class="math inline">\(y_{ij} = \color{red}{\mu_j}+\varepsilon_{ij}.\)</span></p></li>
</ul>
<p><b><font color='purple'>Reference-coded Version</font></b></p>
<ul>
<li><p><span class="math inline">\(H_0: \color{purple}{\boldsymbol{\tau_2 \ldots \tau_J = 0}}\)</span>          <span class="math inline">\(H_A: \color{purple}{\text{ Not all } \tau_j \text{ equal 0}}\)</span></p></li>
<li><p>Null hypothesis in words: No deviation of the true mean for any groups from the baseline group.</p></li>
<li><p>Null model: <span class="math inline">\(y_{ij} =\boldsymbol{\alpha} +\varepsilon_{ij}\)</span></p></li>
<li><p>Alternative hypothesis in words: At least one of the true deviations is different from 0 or that at least one group has a different true mean than the baseline group.</p></li>
<li><p>Alternative model: <span class="math inline">\(y_{ij} =\color{purple}{\boldsymbol{\alpha + \tau_j}}+\varepsilon_{ij}\)</span></p></li>
</ul>
<p>In order to estimate the models discussed above, the <code>lm</code> function is used<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a>. The <code>lm</code> function continues to use the same format as previous functions, <code>lm(Y~X, data=datasetname)</code>. It ends up that this code will give you the reference-coded version of the model by default (The developers of R thought it was that important!). We want to start with the cell-means version of the model, so we have to override the standard technique and add a “<code>-1</code>” to the formula interface to tell R that we want to the cell-means coding. Generally, this looks like <code>lm(Y~X-1, data=datasetname).</code> Once we fit a model in R, the <code>summary</code> function run on the model provides a useful “summary” of the model coefficients and a suite of other potentially interesting information. For the moment, we will focus on the estimated model coefficients, so only those lines are output. When fitting this version of the One-Way ANOVA model, you will find a row of output for each group relating the <span class="math inline">\(\mu_j\text{&#39;s}\)</span>. The output contains columns for an estimate (<code>Estimate</code>), standard error (<code>Std. Error</code>), <span class="math inline">\(t\)</span>-value (<code>t value</code>), and p-value (<code>Pr(&gt;|t|)</code>). We’ll learn to use all the output in the following material, but for now just focus on the estimates of the parameters that the function provides in the first column (“Estimate”) of the coefficient table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr<span class="op">-</span><span class="dv">1</span>, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm1)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##                  Estimate Std. Error  t value     Pr(&gt;|t|)
## AttrBeautiful    4.333333  0.5729959 7.562590 1.225982e-11
## AttrAverage      3.973684  0.5804864 6.845439 4.412410e-10
## AttrUnattractive 5.810811  0.5882785 9.877653 6.857681e-17</code></pre>
<p>In general, we denote estimated parameters with a hat over the parameter of interest to show that it is an estimate. For the true mean of group <span class="math inline">\(j\)</span>, <span class="math inline">\(\mu_j\)</span>, we estimate it with <span class="math inline">\(\hat{\mu}_j\)</span>, which is just the sample mean for group <span class="math inline">\(j\)</span>, <span class="math inline">\(\bar{x}_j\)</span>. The model suggests an estimate for each observation that we denote as <span class="math inline">\(\hat{y}_{ij}\)</span> that we will also call a <strong><em>fitted value</em></strong> based on the model being considered. The same estimate is used for all observations in the each group. R tries to help you to sort out which row of output corresponds to which group by appending the group name with the variable name. Here, the variable name was <code>Attr</code> and the first group alphabetically was <em>Beautiful</em>, so R provides a row labeled <code>AttrBeautiful</code> with an estimate of 4.3333. The sample means from the three groups can be seen to directly match for that group and the other two.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##     4.333333     3.973684     5.810811</code></pre>
<p>The reference-coded version of the same model is more complicated but ends up giving the same results once we understand what it is doing. It uses a different parameterization to accomplish this, so has different model output. Here is the model summary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm2)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##                    Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)       4.3333333  0.5729959  7.5625901 1.225982e-11
## AttrAverage      -0.3596491  0.8156524 -0.4409343 6.601182e-01
## AttrUnattractive  1.4774775  0.8212161  1.7991335 7.471470e-02</code></pre>
<p>The estimated model coefficients are <span class="math inline">\(\hat{\alpha} = 4.333\)</span> years, <span class="math inline">\(\hat{\tau}_2 =-0.3596\)</span> years, <span class="math inline">\(\hat{\tau}_3=1.4775\)</span> years where R selected group 1 for <em>Beautiful</em>, 2 for <em>Average</em>, and 3 for <em>Unattractive</em>. The way you can figure out the baseline group (group 1 is <em>Beautiful</em> here) is to see which category label is <em>not present</em> in the output. <strong>The baseline level is typically the first group label alphabetically</strong>, but you should always check this. Based on these definitions, there are interpretations available for each coefficient. For <span class="math inline">\(\hat{\alpha} = 4.333\)</span> years, this is an estimate of the mean sentencing time for the <em>Beautiful</em> group. <span class="math inline">\(\hat{\tau}_2 =-0.3596\)</span> years is the deviation of the <em>Average</em> group’s mean from the <em>Beautiful</em> group’s mean (specifically, it is <span class="math inline">\(0.36\)</span> years lower). Finally, <span class="math inline">\(\hat{\tau}_3=1.4775\)</span> years tells us that the <em>Unattractive</em> group mean sentencing time is 1.48 years higher than the <em>Beautiful</em> group mean sentencing time. These interpretations lead directly to reconstructing the estimated means for each group by combining the baseline and pertinent deviations as shown in Table <a href="3-2-section3-2.html#tab:Table3-1">2.4</a>.</p>

<table>
<caption><span id="tab:Table3-1">Table 2.4: </span> Constructing group mean estimates from the reference-coded linear model estimates.</caption>
<colgroup>
<col width="20%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Group</th>
<th align="left">Formula</th>
<th align="left">Estimates</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Beautiful</td>
<td align="left"><span class="math inline">\(\hat{\alpha}\)</span></td>
<td align="left"><strong>4.3333</strong> years</td>
</tr>
<tr class="even">
<td align="left">Average</td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_2\)</span></td>
<td align="left">4.3333 - 0.3596 = <strong>3.974</strong> years</td>
</tr>
<tr class="odd">
<td align="left">Unattractive</td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_3\)</span></td>
<td align="left">4.3333 + 1.4775 = <strong>5.811</strong> years</td>
</tr>
</tbody>
</table>
<p>We can also visualize the results of our linear models using what are called <strong><em>term-plots</em></strong> or <strong><em>effect-plots</em></strong> (from the <code>effects</code> package; <span class="citation">(Fox et al. <a href="#ref-R-effects">2018</a>)</span>) as displayed in Figure <a href="3-2-section3-2.html#fig:Figure3-2">2.24</a>. We don’t want to use the word “effect” for these model components unless we have random assignment in the study design so we generically call these <strong><em>term-plots</em></strong> as they display terms or components from the model in hopefully useful ways to aid in model interpretation even in the presence of complicated model parameterizations. Specifically, these plots take an estimated model and show you its estimates along with 95% confidence intervals generated by the linear model. To make this plot, you need to install and load the <code>effects</code> package and then use <code>plot(allEffects(...))</code> functions together on the <code>lm</code> object called <code>lm2</code> that was estimated above. You can find the correspondence between the displayed means and the estimates that were constructed in Table <a href="3-2-section3-2.html#tab:Table3-1">2.4</a>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(lm2))</code></pre></div>
<div class="figure"><span id="fig:Figure3-2"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-2-1.png" alt="Plot of the estimated group mean sentences from the reference-coded model for the MockJury data from the effects package." width="384" />
<p class="caption">
Figure 2.24: Plot of the estimated group mean sentences from the reference-coded model for the MockJury data from the <code>effects</code> package.
</p>
</div>
<p>In order to assess evidence for having different means for the groups, we will compare either of the previous models (cell-means or reference-coded) to a null model based on the null hypothesis (<span class="math inline">\(H_0: \mu_1 = \ldots = \mu_J\)</span>) which implies a model of <span class="math inline">\(\color{red}{y_{ij} = \mu_j}+\varepsilon_{ij}\)</span> in the cell-means version where <span class="math inline">\({\color{red}{\mu}}\)</span> is a common mean for all the observations. We will call this the <b><font color='red'>mean-only</font></b> model since it only has a single mean in it. In the reference-coded version of the model, we have a null hypothesis that <span class="math inline">\(H_0: \tau_2 = \ldots = \tau_J = 0\)</span>, so the “mean-only” model is <span class="math inline">\(\color{purple}{y_{ij} =\boldsymbol{\alpha}+\varepsilon_{ij}}\)</span> with <span class="math inline">\(\color{purple}{\boldsymbol{\alpha}}\)</span> having the same definition as <span class="math inline">\(\color{red}{\mu}\)</span> for the cell means model – it forces a common value for the mean for all the groups. Moving from the <em>reference-coded</em> model to the <em>mean-only</em> model is also an example of a situation where we move from a “full” model to a “reduced” model by setting some coefficients in the “full” model to 0 and, by doing this, get a simpler or “reduced” model. Simple models can be good as they are easier to interpret, but having a model for <span class="math inline">\(J\)</span> groups that suggests no difference in the groups is not a very exciting result in most, but not all, situations<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a>. In order for R to provide results for the mean-only model, we remove the grouping variable, <code>Attr</code>, from the model formula and just include a “1”. The <code>(Intercept)</code> row of the output provides the estimate for the mean-only model as a reduced model from either the cell-means or reference-coded models when we assume that the mean is the same for all groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span><span class="dv">1</span>, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm3)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept) 4.692982  0.3403532 13.78857 5.765681e-26</code></pre>
<p>This model provides an estimate of the common mean for all observations of <span class="math inline">\(4.693 = \hat{\mu} = \hat{\alpha}\)</span> years. This value also is the dashed, horizontal line in the beanplot in Figure <a href="3-1-section3-1.html#fig:Figure3-1">2.23</a>. Some people call this mean-only model estimate the grand or overall mean.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-effects">
<p>Fox, John, Sanford Weisberg, Michael Friendly, and Jangman Hong. 2018. <em>Effects: Effect Displays for Linear, Generalized Linear, and Other Models</em>. <a href="https://CRAN.R-project.org/package=effects" class="uri">https://CRAN.R-project.org/package=effects</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="38">
<li id="fn38"><p>If you look closely in the code for the rest of the book, any model for a quantitative response will use this function, suggesting a common thread in the most commonly used statistical models.<a href="3-2-section3-2.html#fnref38">↩</a></p></li>
<li id="fn39"><p>Suppose we were doing environmental monitoring and were studying asbestos levels in soils. We might be hoping that the mean-only model were reasonable to use if the groups being compared were in remediated areas and in areas known to have never been contaminated.<a href="3-2-section3-2.html#fnref39">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="3-1-section3-1.html"><button class="btn btn-default">Previous</button></a>
<a href="3-3-section3-3.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
