<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R" />
<meta property="og:type" content="book" />


<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R">

<title>8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if bootstrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover" id="toc-cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments" id="toc-acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1" id="toc-chapter1"><span class="toc-section-number">1</span> Preface</a>
<ul>
<li><a href="1.1-section1-1.html#section1-1" id="toc-section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1.2-section1-2.html#section1-2" id="toc-section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1.3-section1-3.html#section1-3" id="toc-section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1.4-section1-4.html#section1-4" id="toc-section1-4"><span class="toc-section-number">1.4</span> Quarto</a></li>
<li><a href="1.5-section1-5.html#section1-5" id="toc-section1-5"><span class="toc-section-number">1.5</span> Grammar of Graphics</a></li>
<li><a href="1.6-section1-6.html#section1-6" id="toc-section1-6"><span class="toc-section-number">1.6</span> Exiting RStudio</a></li>
<li><a href="1.7-section1-7.html#section1-7" id="toc-section1-7"><span class="toc-section-number">1.7</span> Chapter summary</a></li>
<li><a href="1.8-section1-8.html#section1-8" id="toc-section1-8"><span class="toc-section-number">1.8</span> Summary of important R code</a></li>
<li><a href="1.9-section1-9.html#section1-9" id="toc-section1-9"><span class="toc-section-number">1.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2" id="toc-chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a>
<ul>
<li><a href="2.1-section2-1.html#section2-1" id="toc-section2-1"><span class="toc-section-number">2.1</span> Data wrangling and density curves</a></li>
<li><a href="2.2-section2-2.html#section2-2" id="toc-section2-2"><span class="toc-section-number">2.2</span> Pirate-plots</a></li>
<li><a href="2.3-section2-3.html#section2-3" id="toc-section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2.4-section2-4.html#section2-4" id="toc-section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2.5-section2-5.html#section2-5" id="toc-section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2.6-section2-6.html#section2-6" id="toc-section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2.7-section2-7.html#section2-7" id="toc-section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2.8-section2-8.html#section2-8" id="toc-section2-8"><span class="toc-section-number">2.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="2.9-section2-9.html#section2-9" id="toc-section2-9"><span class="toc-section-number">2.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2.10-section2-10.html#section2-10" id="toc-section2-10"><span class="toc-section-number">2.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2.11-section2-11.html#section2-11" id="toc-section2-11"><span class="toc-section-number">2.11</span> Chapter summary</a></li>
<li><a href="2.12-section2-12.html#section2-12" id="toc-section2-12"><span class="toc-section-number">2.12</span> Summary of important R code</a></li>
<li><a href="2.13-section2-13.html#section2-13" id="toc-section2-13"><span class="toc-section-number">2.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3" id="toc-chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a>
<ul>
<li><a href="3.1-section3-1.html#section3-1" id="toc-section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3.2-section3-2.html#section3-2" id="toc-section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell means and reference-coding)</a></li>
<li><a href="3.3-section3-3.html#section3-3" id="toc-section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3.4-section3-4.html#section3-4" id="toc-section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3.5-section3-5.html#section3-5" id="toc-section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3.6-section3-6.html#section3-6" id="toc-section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3.7-section3-7.html#section3-7" id="toc-section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="3.8-section3-8.html#section3-8" id="toc-section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3.9-section3-9.html#section3-9" id="toc-section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3.10-section3-10.html#section3-10" id="toc-section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4" id="toc-chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a>
<ul>
<li><a href="4.1-section4-1.html#section4-1" id="toc-section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4.2-section4-2.html#section4-2" id="toc-section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4.3-section4-3.html#section4-3" id="toc-section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4.4-section4-4.html#section4-4" id="toc-section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4.5-section4-5.html#section4-5" id="toc-section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4.6-section4-6.html#section4-6" id="toc-section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="4.7-section4-7.html#section4-7" id="toc-section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4.8-section4-8.html#section4-8" id="toc-section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4.9-section4-9.html#section4-9" id="toc-section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5" id="toc-chapter5"><span class="toc-section-number">5</span> Chi-square tests</a>
<ul>
<li><a href="5.1-section5-1.html#section5-1" id="toc-section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="5.2-section5-2.html#section5-2" id="toc-section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5.3-section5-3.html#section5-3" id="toc-section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5.4-section5-4.html#section5-4" id="toc-section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5.5-section5-5.html#section5-5" id="toc-section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5.6-section5-6.html#section5-6" id="toc-section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5.7-section5-7.html#section5-7" id="toc-section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5.8-section5-8.html#section5-8" id="toc-section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5.9-section5-9.html#section5-9" id="toc-section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5.10-section5-10.html#section5-10" id="toc-section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5.11-section5-11.html#section5-11" id="toc-section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5.12-section5-12.html#section5-12" id="toc-section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5.13-section5-13.html#section5-13" id="toc-section5-13"><span class="toc-section-number">5.13</span> Summary of important R code</a></li>
<li><a href="5.14-section5-14.html#section5-14" id="toc-section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6" id="toc-chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a>
<ul>
<li><a href="6.1-section6-1.html#section6-1" id="toc-section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6.2-section6-6.html#section6-6" id="toc-section6-6"><span class="toc-section-number">6.2</span> Describing relationships with a regression model</a></li>
<li><a href="6.3-section6-7.html#section6-7" id="toc-section6-7"><span class="toc-section-number">6.3</span> Least Squares Estimation</a></li>
<li><a href="6.4-section6-8.html#section6-8" id="toc-section6-8"><span class="toc-section-number">6.4</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6.5-section6-9.html#section6-9" id="toc-section6-9"><span class="toc-section-number">6.5</span> Outliers: leverage and influence</a></li>
<li><a href="6.6-section6-10.html#section6-10" id="toc-section6-10"><span class="toc-section-number">6.6</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6.7-section6-11.html#section6-11" id="toc-section6-11"><span class="toc-section-number">6.7</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6.8-section6-12.html#section6-12" id="toc-section6-12"><span class="toc-section-number">6.8</span> Chapter summary</a></li>
<li><a href="6.9-section6-13.html#section6-13" id="toc-section6-13"><span class="toc-section-number">6.9</span> Summary of important R code</a></li>
<li><a href="6.10-section6-14.html#section6-14" id="toc-section6-14"><span class="toc-section-number">6.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7" id="toc-chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a>
<ul>
<li><a href="7.1-section7-1.html#section7-1" id="toc-section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7.2-section7-2.html#section7-2" id="toc-section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7.3-section7-3.html#section7-3" id="toc-section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7.4-section7-4.html#section7-4" id="toc-section7-4"><span class="toc-section-number">7.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="7.5-section7-5.html#section7-5" id="toc-section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7.6-section7-6.html#section7-6" id="toc-section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7.7-section7-7.html#section7-7" id="toc-section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7.8-section7-8.html#section7-8" id="toc-section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7.9-section7-9.html#section7-9" id="toc-section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7.10-section7-10.html#section7-10" id="toc-section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8" id="toc-chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a>
<ul>
<li><a href="8.1-section8-1.html#section8-1" id="toc-section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8.2-section8-2.html#section8-2" id="toc-section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8.3-section8-3.html#section8-3" id="toc-section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8.4-section8-4.html#section8-4" id="toc-section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8.5-section8-5.html#section8-5" id="toc-section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8.6-section8-6.html#section8-6" id="toc-section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8.7-section8-7.html#section8-7" id="toc-section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8.8-section8-8.html#section8-8" id="toc-section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8.9-section8-9.html#section8-9" id="toc-section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8.10-section8-10.html#section8-10" id="toc-section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8.11-section8-11.html#section8-11" id="toc-section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8.12-section8-12.html#section8-12" id="toc-section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8.13-section8-13.html#section8-13" id="toc-section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8.14-section8-14.html#section8-14" id="toc-section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8.15-section8-15.html#section8-15" id="toc-section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8.16-section8-16.html#section8-16" id="toc-section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8.17-section8-17.html#section8-17" id="toc-section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9" id="toc-chapter9"><span class="toc-section-number">9</span> Case studies</a>
<ul>
<li><a href="9.1-section9-1.html#section9-1" id="toc-section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9.2-section9-2.html#section9-2" id="toc-section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9.3-section9-3.html#section9-3" id="toc-section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9.4-section9-4.html#section9-4" id="toc-section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9.5-section9-5.html#section9-5" id="toc-section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9.6-section9-6.html#section9-6" id="toc-section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-10" class="section level2" number="8.10">
<h2><span class="header-section-number">8.10</span> Additive MLR with more than two groups: Headache example</h2>
<p>The same techniques can be extended to more than two groups. A study was
conducted to explore sound tolerances using <span class="math inline">\(n = 98\)</span> subjects with the data
available in the <code>Headache</code> data set from the <code>heplots</code> package
<span class="citation">(<a href="#ref-R-heplots">Friendly, Fox, and Monette 2024</a>)</span>. Each subject was initially
exposed to a tone, stopping when the tone became definitely intolerable (<em>DU</em>)
and that decibel level was recorded (variable called <code>du1</code>). Then the subjects
were randomly assigned to one of four treatments: <em>T1</em> (Listened again to the
tone at their initial <em>DU</em> level, for the same amount of time they were able to
tolerate it before); <em>T2</em> (Same as <em>T1</em>, with one additional minute of
exposure); <em>T3</em> (Same as <em>T2</em>, but the subjects were explicitly instructed to
use the relaxation techniques); and <em>Control</em> (these subjects experienced no
further exposure to the noise tone until the final sensitivity measures were
taken). Then the <em>DU</em> was measured again (variable called <code>du2</code>). One would
expect that there would be a relationship between the upper tolerance levels of
the subjects before and after treatment. But maybe the treatments impact that
relationship? We can use our indicator approach to see if the
treatments provide a shift to higher tolerances after accounting for the
relationship between the two measurements<a href="#fn144" class="footnote-ref" id="fnref144"><sup>144</sup></a>. The scatterplot<a href="#fn145" class="footnote-ref" id="fnref145"><sup>145</sup></a> of the results
in Figure <a href="8.10-section8-10.html#fig:Figure8-26">8.26</a> shows some variation in the slopes and the
intercepts for the groups although the variation in intercepts seems more
prominent than differences in slopes. Note that the <code>fct_relevel</code> function was
applied to the <code>treatment</code> variable with an option of <code>"Control"</code> to make
the <em>Control</em> category the baseline category as the person who created the data
set had set <code>T1</code> as the baseline in the <code>treatment</code> variable.</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="8.10-section8-10.html#cb760-1" tabindex="-1"></a><span class="fu">library</span>(heplots)</span>
<span id="cb760-2"><a href="8.10-section8-10.html#cb760-2" tabindex="-1"></a><span class="fu">data</span>(Headache)</span>
<span id="cb760-3"><a href="8.10-section8-10.html#cb760-3" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(Headache)</span>
<span id="cb760-4"><a href="8.10-section8-10.html#cb760-4" tabindex="-1"></a>Headache</span></code></pre></div>
<pre><code>## # A tibble: 98 × 6
##    type    treatment    u1   du1    u2   du2
##    &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 Migrane T3         2.34  5.3   5.8   8.52
##  2 Migrane T1         2.73  6.85  4.68  6.68
##  3 Tension T1         0.37  0.53  0.55  0.84
##  4 Migrane T3         7.5   9.12  5.7   7.88
##  5 Migrane T3         4.63  7.21  5.63  6.75
##  6 Migrane T3         3.6   7.3   4.83  7.32
##  7 Migrane T2         2.45  3.75  2.5   3.18
##  8 Migrane T1         2.31  3.25  2     3.3 
##  9 Migrane T1         1.38  2.33  2.23  3.98
## 10 Tension T3         0.85  1.42  1.37  1.89
## # ℹ 88 more rows</code></pre>
<!-- \newpage -->

<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="8.10-section8-10.html#cb762-1" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> Headache <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">treatment =</span> <span class="fu">factor</span>(treatment),</span>
<span id="cb762-2"><a href="8.10-section8-10.html#cb762-2" tabindex="-1"></a>                                <span class="at">treatment =</span> <span class="fu">fct_relevel</span>(treatment, <span class="st">&quot;Control&quot;</span>)</span>
<span id="cb762-3"><a href="8.10-section8-10.html#cb762-3" tabindex="-1"></a>                                )</span>
<span id="cb762-4"><a href="8.10-section8-10.html#cb762-4" tabindex="-1"></a><span class="co"># Make treatment a factor and Control the baseline category</span></span>
<span id="cb762-5"><a href="8.10-section8-10.html#cb762-5" tabindex="-1"></a>Headache <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> du1, <span class="at">y =</span> du2, <span class="at">color =</span> treatment, </span>
<span id="cb762-6"><a href="8.10-section8-10.html#cb762-6" tabindex="-1"></a>                                  <span class="at">shape =</span> treatment)) <span class="sc">+</span></span>
<span id="cb762-7"><a href="8.10-section8-10.html#cb762-7" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span> </span>
<span id="cb762-8"><a href="8.10-section8-10.html#cb762-8" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb762-9"><a href="8.10-section8-10.html#cb762-9" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb762-10"><a href="8.10-section8-10.html#cb762-10" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.85</span>, <span class="at">option =</span> <span class="st">&quot;inferno&quot;</span>) <span class="sc">+</span> </span>
<span id="cb762-11"><a href="8.10-section8-10.html#cb762-11" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of Maximum DB tolerance before &amp; </span></span>
<span id="cb762-12"><a href="8.10-section8-10.html#cb762-12" tabindex="-1"></a><span class="st">       after treatment (by treatment)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-26"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-26-1.png" alt="Scatterplot of post-treatment decibel tolerance (du2) vs pre-treatment tolerance (du1) by treatment level (4 groups)." width="75%" />
<p class="caption">
Figure 8.26: Scatterplot of post-treatment decibel tolerance (du2) vs pre-treatment tolerance (du1) by treatment level (4 groups).
</p>
</div>
<p>This data set contains a categorical variable with 4 levels. To go beyond two
groups, we have to add more than one indicator variable, defining three
indicators to turn on (1) or off (0) for three of the levels of the variable
with the same reference level used for all the indicators. For this example,
the <em>Control</em> group is chosen as the baseline group so it hides in
the background while we define indicators for the other three levels. The
indicators for <em>T1</em>, <em>T2</em>, and <em>T3</em> treatment levels are:</p>
<ul>
<li><p>Indicator for <em>T1</em>: <span class="math inline">\(I_{T1,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T1 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>T2</em>: <span class="math inline">\(I_{T2,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T2 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>T3</em>: <span class="math inline">\(I_{T3,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T3 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
</ul>
<p>We can see the values of these indicators for a few observations and their
original variable (<code>treatment</code>) in the following output. For <em>Control</em> all the
indicators stay at 0.</p>
<!-- \newpage -->
<table>
<thead>
<tr class="header">
<th align="left">Treatment</th>
<th align="right">I_T1</th>
<th align="right">I_T2</th>
<th align="right">I_T3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Control</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>When we fit the additive model of the form <code>y ~ x + group</code>, the <code>lm</code>
function takes the <span class="math inline">\(\boldsymbol{J}\)</span> categories and creates <span class="math inline">\(\boldsymbol{J-1}\)</span>
indicator variables.
The baseline level is always handled in the intercept.
The true model will be of the form</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_i +\beta_2I_{\text{Level}2,i}+\beta_3I_{\text{Level}3,i}
+\cdots+\beta_{J}I_{\text{Level}J,i}+\varepsilon_i\]</span></p>
<p>where the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> are the different indicator variables.
Note that each indicator variable gets a coefficient associated with it and is
“turned on” whenever the <span class="math inline">\(i^{th}\)</span> observation is in that category. At most only one of
the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> is a 1 for any observation, so the
<span class="math inline">\(y\)</span>-intercept will either be <span class="math inline">\(\beta_0\)</span> for the baseline group or <span class="math inline">\(\beta_0+\beta_j\)</span>
for <span class="math inline">\(j = 2,\ldots,J\)</span>. It is important to remember that this
is an “additive” model since the effects just add and there is no interaction
between the grouping variable and the quantitative predictor. To be able to
trust this model, we need to check that we do not need different slope
coefficients for the groups as discussed in the next section.</p>
<p>For these types of models, it is always good to start with a plot of the data
set with regression lines for each group – assessing whether the lines look
relatively parallel or not.
In Figure <a href="8.10-section8-10.html#fig:Figure8-26">8.26</a>, there are some
differences in slopes – we investigate that further in the next section. For
now, we can proceed with fitting the additive model with different intercepts
for the four levels of <code>treatment</code> and the quantitative explanatory variable, <code>du1</code>.</p>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb763-1"><a href="8.10-section8-10.html#cb763-1" tabindex="-1"></a>head1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1 <span class="sc">+</span> treatment, <span class="at">data =</span> Headache)</span>
<span id="cb763-2"><a href="8.10-section8-10.html#cb763-2" tabindex="-1"></a><span class="fu">summary</span>(head1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1 + treatment, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9085 -0.9551 -0.3118  1.1141 10.5364 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.25165    0.51624   0.487   0.6271
## du1          0.83705    0.05176  16.172   &lt;2e-16
## treatmentT1  0.55752    0.61830   0.902   0.3695
## treatmentT2  0.63444    0.63884   0.993   0.3232
## treatmentT3  1.36671    0.60608   2.255   0.0265
## 
## Residual standard error: 2.14 on 93 degrees of freedom
## Multiple R-squared:  0.7511, Adjusted R-squared:  0.7404 
## F-statistic: 70.16 on 4 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The complete estimated regression model is</p>
<p><span class="math display">\[\widehat{\text{du2}}_i = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i}\]</span></p>
<p>For each group, the model simplifies to an SLR as follows:</p>
<ul>
<li>For <em>Control</em> (baseline):</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp; = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i} \\
&amp; = 0.252+0.837\cdot\text{du1}_i+0.558*0+0.634*0+1.367*0 \\
&amp; = 0.252+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>
<ul>
<li>For <em>T1</em>:</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp; = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i} \\
&amp; = 0.252+0.837\cdot\text{du1}_i+0.558*1+0.634*0+1.367*0 \\
&amp; = 0.252+0.837\cdot\text{du1}_i + 0.558 \\
&amp; = 0.81+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>
<!-- \newpage -->
<ul>
<li>Similarly for <em>T2</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 0.886 + 0.837\cdot\text{du1}_i\]</span></p>
<ul>
<li>Finally for <em>T3</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 1.62 + 0.837\cdot\text{du1}_i\]</span></p>
<p>To reinforce what this additive model is doing, Figure <a href="8.10-section8-10.html#fig:Figure8-27">8.27</a>
displays the estimated regression lines for all four
groups, showing the shifts in the <em>y</em>-intercepts among the groups.
</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-27"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-27-1.png" alt="Plot of estimated noise tolerance additive model." width="75%" />
<p class="caption">
Figure 8.27: Plot of estimated noise tolerance additive model.
</p>
</div>
<p>The right panel of the term-plot (Figure <a href="8.10-section8-10.html#fig:Figure8-28">8.28</a>) shows
how the <em>T3</em> group seems to have shifted up the most relative to
the others and the <em>Control</em> group seems to have a mean that is a bit lower than
the others, in the model that otherwise assumes that the same linear
relationship holds between <code>du1</code> and <code>du2</code> for all the groups. After
controlling for the <em>Treatment</em> group, for a 1 decibel increase in initial
tolerances, we estimate, on average, to obtain a 0.84 decibel change in the
second tolerance measurement. The <strong><em>R</em></strong><sup>2</sup> shows that this is a decent model
for the responses, with this model explaining 75.1% percent of the
variation in the second decibel tolerance measure. We should check the
diagnostic plots and VIFs to check for any issues – all the diagnostics and
assumptions are as before except that there is no assumption of linearity
between the grouping variable and the responses.
Additionally, sometimes we need to add group information to diagnostics to see
if any patterns in residuals look different in different groups, like linearity
or non-constant variance, when we are fitting models that might contain multiple
groups.</p>

<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb765-1"><a href="8.10-section8-10.html#cb765-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(head1, <span class="at">residuals =</span> T), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-28"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-28-1.png" alt="Term-plots of the additive decibel tolerance model with partial residuals." width="75%" />
<p class="caption">
Figure 8.28: Term-plots of the additive decibel tolerance model with partial residuals.
</p>
</div>
<p>The diagnostic plots in Figure <a href="8.10-section8-10.html#fig:Figure8-29">8.29</a> provides some
indications of a few observations in the tails that deviate from a normal
distribution to having slightly heavier tails but only one outlier is of real
concern and causes some concern about the normality assumption. There is a small
indication of increasing variability as a function of the fitted values as both
the Residuals vs. Fitted and Scale-Location plots show some fanning out for
higher values but this is a minor issue. There are no influential points here
since all the Cook’s D values are less than 0.5. </p>

<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="8.10-section8-10.html#cb766-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>,<span class="dv">0</span>))</span>
<span id="cb766-2"><a href="8.10-section8-10.html#cb766-2" tabindex="-1"></a><span class="fu">plot</span>(head1, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">sub.caption =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb766-3"><a href="8.10-section8-10.html#cb766-3" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">&quot;Plot of diagnostics for additive model with du1 and </span></span>
<span id="cb766-4"><a href="8.10-section8-10.html#cb766-4" tabindex="-1"></a><span class="st">     treatment for du2&quot;</span>, <span class="at">outer=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-29"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-29-1.png" alt="Diagnostic plots for the additive decibel tolerance model." width="75%" />
<p class="caption">
Figure 8.29: Diagnostic plots for the additive decibel tolerance model.
</p>
</div>
<p>Additionally, sometimes we need to add group information to diagnostics
to see if any patterns in residuals look different in different groups, like
linearity or non-constant variance, when we are fitting models that might
contain multiple groups. We can use the same scatterplot tools to make our own
plot of the residuals (extracted using the <code>residuals</code> function) versus the
fitted values (extracted using the <code>fitted</code> function) by groups as in
Figure <a href="8.10-section8-10.html#fig:Figure8-30">8.30</a>. This provides an opportunity to introduce
faceting, where we can split our plots into panels by a grouping variable, here
by the <code>treatment</code> applied to each subject.
This can be helpful with multiple groups to be able
to see each one more clearly as we avoid overplotting. The addition of
<code>+ facet_grid(cols = vars(treatment))</code> facets the plot based on the
<code>treatment</code> variable and puts the facets in different columns because of the
<code>cols =</code> part of the code (<code>rows =</code> specifies the number of rows for the
facets), labeling each panel at the top with the level being displayed of the
faceting variable (<code>vars()</code> is needed to help ggplot find the variable). In
this example, there are no additional patterns identified by making this plot
although we do see some minor deviations in the fitted lines for each group,
but it is a good additional check in these multi-group situations.</p>

<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb767-1"><a href="8.10-section8-10.html#cb767-1" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> Headache <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">resids =</span> <span class="fu">residuals</span>(head1),</span>
<span id="cb767-2"><a href="8.10-section8-10.html#cb767-2" tabindex="-1"></a>                                <span class="at">fits =</span> <span class="fu">fitted</span>(head1)</span>
<span id="cb767-3"><a href="8.10-section8-10.html#cb767-3" tabindex="-1"></a>                                )</span>
<span id="cb767-4"><a href="8.10-section8-10.html#cb767-4" tabindex="-1"></a>Headache <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> resids, </span>
<span id="cb767-5"><a href="8.10-section8-10.html#cb767-5" tabindex="-1"></a>                                  <span class="at">color =</span> treatment, <span class="at">shape =</span> treatment)) <span class="sc">+</span></span>
<span id="cb767-6"><a href="8.10-section8-10.html#cb767-6" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb767-7"><a href="8.10-section8-10.html#cb767-7" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb767-8"><a href="8.10-section8-10.html#cb767-8" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb767-9"><a href="8.10-section8-10.html#cb767-9" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.85</span>, <span class="at">option =</span> <span class="st">&quot;inferno&quot;</span>) <span class="sc">+</span></span>
<span id="cb767-10"><a href="8.10-section8-10.html#cb767-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of Residuals vs Fitted by Treatment Group&quot;</span>) <span class="sc">+</span></span>
<span id="cb767-11"><a href="8.10-section8-10.html#cb767-11" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">cols =</span> <span class="fu">vars</span>(treatment))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-30"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-30-1.png" alt="Faceted scatterplot of residuals versus fitted values by treatment group from the additive decibel tolerance model." width="75%" />
<p class="caption">
Figure 8.30: Faceted scatterplot of residuals versus fitted values by treatment group from the additive decibel tolerance model.
</p>
</div>
<p>The VIFs are different for models with categorical variables than for models with only quantitative
predictors in MLR, even though we are still concerned with shared information across the predictors of all kinds. For categorical predictors, the <span class="math inline">\(J\)</span> levels are combined to create a single measure for the predictor all together called the
<strong><em>generalized VIF (GVIF)</em></strong>. For GVIFs, interpretations are based on the GVIF measure to the power <span class="math inline">\(1/(2*(J-1))\)</span>. For quantitative predictors when GVIFS are present, <span class="math inline">\(J\)</span> = 2, and the power simplifies to <span class="math inline">\(1/2\)</span>, which is our regular square-root scale for inflation of standard errors due to multicollinearity (so the GVIF is the VIF for quantitative predictors). For a <span class="math inline">\(J\)</span>-level categorical predictor, the power is also <span class="math inline">\(1/2\)</span> for <span class="math inline">\(J=2\)</span> levels and increases for more levels. There are no rules of thumb for GVIFs for <span class="math inline">\(J&gt;2\)</span>. In the following output, there are four levels, so <span class="math inline">\(J=4\)</span>. When raised to the requisite power, the GVIF interpretation for multi-category categorical predictors is <strong>the
multiplicative increase in the SEs for the coefficients on all the indicator
variables due to multicollinearity with other predictors</strong>. In this model, the
SE for the quantitative predictor <code>du1</code> is 1.009 times larger due to multicollinearity with other
predictors and the SEs for the indicator variables for the four-level categorical <code>treatment</code> predictor are 1.003
times larger due to multicollinearity, both compared to what they would have been with no shared information in the predictors in the model. Neither are large, so multicollinearity is not a problem in this model.</p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="8.10-section8-10.html#cb768-1" tabindex="-1"></a><span class="fu">vif</span>(head1)</span></code></pre></div>
<pre><code>##              GVIF Df GVIF^(1/(2*Df))
## du1       1.01786  1        1.008891
## treatment 1.01786  3        1.002955</code></pre>
<p>While there are inferences available in the model output, the tests for
the indicator variables are not too informative (at least to start) since they
only compare each group to the baseline. In Section <a href="8.12-section8-12.html#section8-12">8.12</a>, we see
how to use ANOVA <em>F</em>-tests to help us ask general questions about including a
categorical predictor in the model. But we can compare adjusted <strong><em>R</em></strong><sup>2</sup>
values with and without <em>Treatment</em> to see if including the categorical
variable was “worth it”:</p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="8.10-section8-10.html#cb770-1" tabindex="-1"></a>head1R <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1, <span class="at">data =</span> Headache)</span></code></pre></div>
<!-- \newpage -->
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="8.10-section8-10.html#cb771-1" tabindex="-1"></a><span class="fu">summary</span>(head1R)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9887 -0.8820 -0.2765  1.1529 10.4165 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.84744    0.36045   2.351   0.0208
## du1          0.85142    0.05189  16.408   &lt;2e-16
## 
## Residual standard error: 2.165 on 96 degrees of freedom
## Multiple R-squared:  0.7371, Adjusted R-squared:  0.7344 
## F-statistic: 269.2 on 1 and 96 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The adjusted <strong><em>R</em></strong><sup>2</sup> in the model with both <em>Treatment</em> and <em>du1</em> is
0.7404 and the adjusted <em>R</em><sup>2</sup> for this reduced model with just <em>du1</em> is 0.7344,
suggesting the <em>Treatment</em> is useful. The next section
provides a technique to be able to work with different slopes on the
quantitative predictor for each group. Comparing those results to the results
for the additive model allows assessment of the assumption in this section that
all the groups had the same slope coefficient for the quantitative variable.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-R-heplots" class="csl-entry">
Friendly, Michael, John Fox, and Georges Monette. 2024. <em>Heplots: Visualizing Hypothesis Tests in Multivariate Linear Models</em>. <a href="http://friendly.github.io/heplots/">http://friendly.github.io/heplots/</a>.
</div>
<div id="ref-R-viridis" class="csl-entry">
Garnier, Simon. 2024. <em>Viridis: Colorblind-Friendly Color Maps for r</em>. <a href="https://sjmgarnier.github.io/viridis/">https://sjmgarnier.github.io/viridis/</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="144">
<li id="fn144"><p>Models like this with a categorical
variable and quantitative variable are often called <em>ANCOVA</em> or <em>analysis of
covariance</em> models but really are just versions of our linear models we’ve been
using throughout this material.<a href="8.10-section8-10.html#fnref144" class="footnote-back">↩︎</a></p></li>
<li id="fn145"><p>The
<code>scale_color_viridis_d(end = 0.85, option = "inferno")</code> code makes the plot
in a suite of four colors from the <code>viridis</code> package <span class="citation">(<a href="#ref-R-viridis">Garnier 2024</a>)</span> that attempt
to be color-blind friendly.<a href="8.10-section8-10.html#fnref145" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8.9-section8-9.html"><button class="btn btn-default">Previous</button></a>
<a href="8.11-section8-11.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
